name: Run 591 Scraper Hourly

on:
  # 每小時的第 0 分鐘執行 (UTC 時區)
  # 對應台灣時間 (UTC+8) 的 08:00 至 22:00
  schedule:
    - cron: '0 0-14 * * *'
  workflow_dispatch:  # 手動觸發

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10      # 防止爬蟲卡住佔用 runner
    steps:
      # Step 1 取回程式碼
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2 設定 Node.js
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'       # 自動快取 node_modules

      # Step 3 安裝依賴
      - name: Install dependencies
        run: npm ci

      # Step 4 安裝 Playwright 瀏覽器（headless Chromium）
      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      # Step 5 執行爬蟲
      - name: Run scraper
        run: node index.js
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
      
      # Step 6 檢查是否有變更，並提交
      - name: Commit and push if data changed
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add 591_data.json
          # 如果檔案沒有變動，git commit  會失敗，所以加上 || exit 0
          git commit -m "Update 591 data" || exit 0
          git push

      # Step 7 （可選）保存執行結果‐log 以利除錯
      - name: Upload log on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-log
          path: |
            playwright*.log
            # 也可自行將 console output redirect 至檔案